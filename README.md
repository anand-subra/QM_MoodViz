# Mood Visualiser

The aim of this UG project is to design a system which makes use of wireless devices, web technologies and biometric sensors to present data in the form of a visualisation that is easily accessible and interpretable by both performer and audience in real time.

Technologies used in this project:
- [Node.js](https://nodejs.org/en/)
- [p5.js](http://p5js.org/) (a JavaScript library based on the Processing language)
- [BITalino Plugged](http://www.bitalino.com/index.php/plugged-kit) health platform
- [BITalino Python API] (https://github.com/BITalinoWorld/python-api)
- [socketIO JS](http://socket.io)
- [socketIO-client(Python)](https://github.com/invisibleroads/socketIO-client)

How to run:
- Run ***live-server*** in Terminal process
- Run ***nodemon server.js*** or ***node server.js*** in another Terminal process
- Run ***python MoodVizBit.py*** in another Terminal process


Created by **Anand Subramaniam**

Lead & Supervised by **Mathieu Barthet**

*Centre for Digital Music,* **Queen Mary University of London**
