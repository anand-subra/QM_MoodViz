# Mood Visualiser

The aim of this UG project is to design a system which makes use of wireless devices, web technologies and biometric sensors to present data in the form of a visualisation that is easily accessible and interpretable by both performer and audience in real time.

Technologies used in this project:
- [Node.js](https://nodejs.org/en/)
- [p5.js](http://p5js.org/) (a JavaScript library based on the Processing language)
- [BITalino Plugged](http://www.bitalino.com/index.php/plugged-kit) health platform
- [BITalino Python API] (https://github.com/BITalinoWorld/python-api)
- [socketIO JS](http://socket.io)
- [socketIO-client(Python)](https://github.com/invisibleroads/socketIO-client)

- Run "live-server" in Terminal window
- Run "nodemon server.js" in another Terminal window
- Run "python sock.py" in another Terminal window


Created by **Anand Subramaniam**

Lead & Supervised by **Mathieu Barthet**

*Centre for Digital Music,* **Queen Mary University of London**
